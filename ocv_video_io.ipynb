{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV MP4 I/O <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import cv2 \n",
    "import glob,os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def display_mp4(fullpath, starttime=0):\n",
    "    cap = cv2.VideoCapture(fullpath)\n",
    "    # get video info\n",
    "    width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps       = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_seq = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    time_value_list = [int(i) for i in starttime.split(':')]\n",
    "    starttime_sec = time_value_list[0]*3600 + time_value_list[1]*60 + time_value_list[2]\n",
    "    frame_to_go = starttime_sec * int(fps)\n",
    "    \n",
    "    cap.set(1,frame_to_go)\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # change color\n",
    "        \"\"\"\n",
    "        f_max_R, f_min_R = np.max(frame[:,:,0]), np.min(frame[:,:,0])\n",
    "        f_max_G, f_min_G = np.max(frame[:,:,1]), np.min(frame[:,:,1])\n",
    "        f_max_B, f_min_B = np.max(frame[:,:,2]), np.min(frame[:,:,2])\n",
    "        #print (f_max, f_min)\n",
    "        R_w, G_w, B_w = 1./3., 1./3., 1./3.\n",
    "        c_ratio = f_max_R*R_w + f_max_G*G_w + f_max_B*B_w\n",
    "        cv2.imshow('frame',frame/float(c_ratio))        \n",
    "        \"\"\"\n",
    "\n",
    "        # change color space\n",
    "        \"\"\"\n",
    "        #img_changed = cv2.cvtColor(frame, cv2.COLOR_BGR2XYZ)\n",
    "        #img_changed = cv2.bilateralFilter(img_changed, d=5, sigmaColor=5, sigmaSpace=2)\n",
    "        cv2.imshow('frame',img_changed)\n",
    "        \"\"\"\n",
    "\n",
    "        # Laplacian edge detection\n",
    "        \"\"\"\n",
    "        frame = cv2.GaussianBlur(frame, ksize=(3,3),sigmaX=1.5)\n",
    "        frame = cv2.addWeighted(frame, 1.5, frame, 1.5, 3.)\n",
    "        frame = cv2.Laplacian(frame,cv2.CV_32F)\n",
    "        #frame =  cv2.convertScaleAbs(frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Sobel edge detection\n",
    "        #frame = cv2.addWeighted(frame, 1., frame, 1., 3.)\n",
    "        frame = cv2.GaussianBlur(frame, ksize=(5,5),sigmaX=30)\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        #gray = cv2.addWeighted(gray,1.4 , gray, 1.4, 3.) \n",
    "        #\n",
    "        gray_sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=5)\n",
    "        gray_sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=5)\n",
    "        #change to unsigned 8 bit int\n",
    "        gray_abs_sobelx = cv2.convertScaleAbs(gray_sobelx) \n",
    "        gray_abs_sobely = cv2.convertScaleAbs(gray_sobely)\n",
    "        gray_sobel_edge = cv2.addWeighted(gray_abs_sobelx ,0.4 ,gray_abs_sobely ,0.4 ,0.) \n",
    "        cv2.imshow('gray_sobel_edge',gray_sobel_edge) \n",
    "        \n",
    "        #cv2.waitKey(0)  # frame-by-frame waiting keystroke\n",
    "        # waitKey val > 1000/25 (40), wait long, display slower than 25frame/sec\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#fullpath = \"/Users/sclc/ds_videos/xinlizui.mp4\"\n",
    "#display_mp4(fullpath,\"01:10:11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html\\nflags = [i for i in dir(cv2) if i.startswith(\\'COLOR_\\')]\\nprint ([i for i in flags if i.startswith(\"COLOR_BGR\")])\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\"\"\"\n",
    "fullpath = \"/Users/sclc/ds_videos/xinlizui.mp4\"\n",
    "cap = cv2.VideoCapture(fullpath)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "print (cap.get(cv2.CAP_PROP_FPS))\n",
    "print (cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_num = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "len_video_sec = int (int(frame_num)/int(fps))\n",
    "print (\"video length \"+str(datetime.timedelta(seconds=len_video_sec)))\n",
    "\n",
    "#print(np.max(frame[:,:,0]), np.min(frame[:,:,0]))\n",
    "\n",
    "#cv2.imshow('frame',frame/55.)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "\"\"\"\n",
    "length = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "print (length, width, height, fps)\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "\"\"\"\n",
    "# http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html\n",
    "flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "print ([i for i in flags if i.startswith(\"COLOR_BGR\")])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_im(path):\n",
    "\n",
    "    #img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.imread(path)\n",
    "\n",
    "    resized = img\n",
    "    #resized = cv2.resize(img, (img_cols, img_rows))\n",
    "\n",
    "    return resized\n",
    "\n",
    "def read_train_data_fullname(filepath):\n",
    "\n",
    "    \n",
    "    files = glob.glob(filepath)\n",
    "    # sorting\n",
    "    filenames = sorted(files, key=lambda x: int(x.split(\"fig\")[-1].split(\"_\")[0]))\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "#filepath = \"/Users/sclc/ds_images/figsTut_at52_20170823_a/*.png\"\n",
    "#filenames=read_train_data_fullname(filepath)\n",
    "#for fl in filenames:\n",
    "    #print(fl)\n",
    "    #print(os.path.basename(fl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output video is ./a.mp4\n"
     ]
    }
   ],
   "source": [
    "def combine_to_video(filenames):\n",
    "    \n",
    "    frame = cv2.imread(filenames[0])\n",
    "    width, height, channels = frame.shape\n",
    "    # Define the codec and create VideoWriter object\n",
    "    video_output = \"./a.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
    "    out = cv2.VideoWriter(video_output, fourcc, 2.0, (width, height))\n",
    "    \n",
    "    for fl in filenames:\n",
    "        frame = cv2.imread(fl)\n",
    "        out.write(frame)\n",
    "        \n",
    "        cv2.imshow('video',frame)\n",
    "        if (cv2.waitKey(1) & 0xFF) == ord('q'): # Hit `q` to exit\n",
    "            break\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # we need to know when the generation finished\n",
    "    print(\"The output video is {}\".format(video_output))\n",
    "\n",
    "filepath = \"/Users/sclc/ds_images/figsTut_at52_20170823_a/*.png\"\n",
    "filenames=read_train_data_fullname(filepath)\n",
    "combine_to_video(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35ocv]",
   "language": "python",
   "name": "conda-env-py35ocv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
